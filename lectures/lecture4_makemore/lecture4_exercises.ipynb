{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f74d22-7eba-4f6e-9835-612bbf0ca015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ Exercise 1 ------------------------------\n",
    "# I did not get around to seeing what happens when you initialize all \n",
    "# weights and biases to zero. Try this and train the neural net. \n",
    "# You might think either that \n",
    "#     1) the network trains just fine or \n",
    "#     2) the network doesn't train at all, but actually it is \n",
    "#     3) the network trains but only partially, and achieves a pretty bad \n",
    "#        final performance. \n",
    "# Inspect the gradients and activations to figure out what is happening \n",
    "# and why the network is only partially training, and what part is being \n",
    "# trained exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e02a4457-a6fe-4a02-82db-25b278162f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa9e1203-41b5-4e2f-8ad8-49a3b8f5dd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dabe25-16eb-492e-9a01-8e265d091ef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d91efd-cd25-4cf7-bc82-f2b9d528bc20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        # print(w)\n",
    "\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "    \n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])       # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte, Yte = build_dataset(words[n2:])   # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df958bb7-b116-4ba4-b3a4-fa7bf69ce12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's train a deeper network\n",
    "\n",
    "class Linear:\n",
    "    \n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "class BatchNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "        # buffers (trained with a running 'momentum update')\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var = torch.ones(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "        if self.training:\n",
    "            xmean = x.mean(0, keepdim=True) # batch mean\n",
    "            xvar = x.var(0, keepdim=True) # batch variance\n",
    "        else:\n",
    "            xmean = self.running_mean\n",
    "            xvar = self.running_var\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        # update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "    \n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "84fd68ca-c064-4fda-9eb3-5c08abaf4c7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47551\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # dimensionality of the character embedding vectors\n",
    "n_hidden = 100 # the number of neurons in the hidden layer of the MLP\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd), generator = g)\n",
    "layers = [\n",
    "    Linear(n_embd * block_size, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, vocab_size), BatchNorm1d(vocab_size)\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # last layer: make less confident\n",
    "    layers[-1].gamma *= 0.1\n",
    "    # layers[-1].weight *= 0.1\n",
    "    # all other layers: apply gain\n",
    "    for layer in layers[:-1]:\n",
    "        if isinstance(layer, Linear):\n",
    "            layer.weight *= 5/3\n",
    "            \n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "006a1aac-4ed5-442e-91ba-d841b1248634",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, Linear):\n",
    "            layer.weight *= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "18645333-0332-4215-9a3a-bb1cffd5cb4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2958\n",
      "  10000/ 200000: 3.0271\n",
      "  20000/ 200000: 2.7633\n",
      "  30000/ 200000: 2.6101\n",
      "  40000/ 200000: 2.8132\n",
      "  50000/ 200000: 2.7690\n",
      "  60000/ 200000: 2.7750\n",
      "  70000/ 200000: 2.8423\n",
      "  80000/ 200000: 2.9841\n",
      "  90000/ 200000: 2.9989\n",
      " 100000/ 200000: 2.8870\n",
      " 110000/ 200000: 2.8799\n",
      " 120000/ 200000: 2.8669\n",
      " 130000/ 200000: 2.5848\n",
      " 140000/ 200000: 2.5401\n",
      " 150000/ 200000: 2.6086\n",
      " 160000/ 200000: 3.0590\n",
      " 170000/ 200000: 2.7276\n",
      " 180000/ 200000: 2.9195\n",
      " 190000/ 200000: 2.6891\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    \n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb, = Xtr[ix], Ytr[ix] # # batch X, Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad() # AFTER_DEBUG: would take out retain_grad\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 1#0.1 if i < 100000 else 0.01 \n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    if i%10000 == 0:\n",
    "        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\n",
    "    lossi.append(loss.log10().item())\n",
    "    with torch.no_grad():\n",
    "        ud.append([(lr*p.grad.std() / p.data.std()).log10().item() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "954dd888-50ea-441c-9e59-fcab6e5f684b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Linear out is 0.0\n",
      "Sum of BatchNorm1d out is 0.0\n",
      "Sum of Tanh out is 0.0\n",
      "Sum of Linear out is 0.0\n",
      "Sum of BatchNorm1d out is 0.0\n",
      "Sum of Tanh out is 0.0\n",
      "Sum of Linear out is 0.0\n",
      "Sum of BatchNorm1d out is 0.0\n",
      "Sum of Tanh out is 0.0\n",
      "Sum of Linear out is 0.0\n",
      "Sum of BatchNorm1d out is 0.0\n",
      "Sum of Tanh out is 0.0\n",
      "Sum of Linear out is 0.0\n",
      "Sum of BatchNorm1d out is 0.0\n",
      "Sum of Tanh out is 0.0\n",
      "Sum of Linear out is 0.08865606784820557\n",
      "Sum of BatchNorm1d out is 0.002830415964126587\n"
     ]
    }
   ],
   "source": [
    "for layer in layers:\n",
    "    print(f'Sum of {layer.__class__.__name__} out is {layer.out.sum()}')\n",
    "    \n",
    "# We can see that we only have visible updates on the last Linear and last BatchNorm1d layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e03e984c-b1e3-4bea-93f3-ccc8de4f95b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16b14ae80>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAMtCAYAAACb3mlVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmIklEQVR4nO3dfWxV93nA8ccQuKGNfZl5sfEwlCRt6EphEk0cKy1rB+OlUlQSIqVpp5EKpUpm0IBm6ZiW0GiVvKXS1nWj6X9hk0rSRSqJEqmpUlKMqgFdqBDLtqDAmCACOy0SvsEZBuGzP6p6c8Kb33LtJ5+PdCR87/G9T/w79+qbq+PjmqIoigAAgEQmVHsAAAAYaSIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkM511R7g3fr6+uLkyZNRW1sbNTU11R4HAIAxoiiKePvtt6OpqSkmTLjyZ7VjLnJPnjwZzc3N1R4DAIAx6sSJEzF79uwr7jPmIre2tjYifj18XV1dlacZmnK5XO0RxrTu7u5qjzAsGdZ3tNcgw89oPBvv6+s9grHOMVp9v+nFK6kZa3/Wt1KpRLlcju7u7nEbuU6zuLIxdsgNWob1He01yPAzGs/G+/p6j2Csc4xW37V0ol88AwAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQzapG7bdu2+MhHPhLXX399tLS0xM9//vPReioAABhgVCL3Bz/4QWzevDm2bt0av/jFL2LRokWxYsWKeOutt0bj6QAAYIBR+WMQLS0tceutt8Y//MM/REREX19fNDc3x4YNG+LP/uzPBuzb29sbvb29/V9XKpVobm72xyAScxHt6hvvfyyAKxvv6+s9grHOMVp9VfljEOfPn48DBw7EsmXL/u9JJkyIZcuWxd69e9+zf3t7e5TL5f6tubl5pEcCAOADZsQj91e/+lVcvHgxGhoaBtze0NAQnZ2d79l/y5Yt0d3d3b+dOHFipEcCAOAD5rpqD1AqlaJUKlV7DAAAEhnxT3KnT58eEydOjK6urgG3d3V1RWNj40g/HQAAvMeIR+7kyZNj8eLFsWvXrv7b+vr6YteuXdHa2jrSTwcAAO8xKqcrbN68OdauXRuf+tSn4rbbbotvf/vb0dPTE1/5yldG4+kAAGCAUYnce++9N375y1/GY489Fp2dnfG7v/u78dJLL73nl9EAAGA0jMp1coejUqlEuVx2ndzExtghN2gZ1ne8X0eVKxvv6+s9grHOMVp9VblOLgAAVJvIBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpjHjkfuMb34iampoB2/z580f6aQAA4LKuG40H/cQnPhE/+clP/u9JrhuVpwEAgEsalfq87rrrorGxcTQeGgAArmpUzsl94403oqmpKW688cb48pe/HMePH7/svr29vVGpVAZsAAAwHCMeuS0tLbF9+/Z46aWX4sknn4xjx47FZz7zmXj77bcvuX97e3uUy+X+rbm5eaRHAgDgA6amKIpiNJ/gzJkzMXfu3Pibv/mbWLdu3Xvu7+3tjd7e3v6vK5VKNDc3R3d3d9TV1Y3maKOmpqam2iOMaaN8yI26DOs72muQ4Wc0no339fUewVjnGK2+a+nEUf+NsKlTp8bHPvaxOHLkyCXvL5VKUSqVRnsMAAA+QEb9Orlnz56No0ePxqxZs0b7qQAAICJGIXIffvjh6OjoiP/+7/+Of/mXf4m77rorJk6cGPfdd99IPxUAAFzSiJ+u8Oabb8Z9990Xp0+fjhkzZsSnP/3p2LdvX8yYMWOknwoAAC5pxCP3mWeeGemHBACAQRn1c3IBAOD9JnIBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDqDjtw9e/bEnXfeGU1NTVFTUxPPPffcgPuLoojHHnssZs2aFVOmTIlly5bFG2+8MVLzAgDAVQ06cnt6emLRokWxbdu2S97/xBNPxHe+85343ve+F/v3748Pf/jDsWLFijh37tywhwUAgGtRUxRFMeRvrqmJnTt3xurVqyPi15/iNjU1xde+9rV4+OGHIyKiu7s7GhoaYvv27fHFL37xqo9ZqVSiXC5Hd3d31NXVDXW0qqqpqan2CGPaMA65MSHD+o72GmT4GY1n4319vUcw1jlGq+9aOnFEz8k9duxYdHZ2xrJly/pvK5fL0dLSEnv37r3k9/T29kalUhmwAQDAcIxo5HZ2dkZERENDw4DbGxoa+u97t/b29iiXy/1bc3PzSI4EAMAHUNWvrrBly5bo7u7u306cOFHtkQAAGOdGNHIbGxsjIqKrq2vA7V1dXf33vVupVIq6uroBGwAADMeIRu68efOisbExdu3a1X9bpVKJ/fv3R2tr60g+FQAAXNZ1g/2Gs2fPxpEjR/q/PnbsWBw8eDDq6+tjzpw5sXHjxvjmN78ZH/3oR2PevHnx6KOPRlNTU/8VGAAAYLQNOnJfffXV+NznPtf/9ebNmyMiYu3atbF9+/Z45JFHoqenJ7761a/GmTNn4tOf/nS89NJLcf3114/c1AAAcAXDuk7uaHCd3PzG2CE3aBnWd7xfR5UrG+/r6z2Csc4xWn3v+3VyAQBgLBC5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACCdQUfunj174s4774ympqaoqamJ5557bsD9999/f9TU1AzYVq5cOVLzAgDAVQ06cnt6emLRokWxbdu2y+6zcuXKOHXqVP/29NNPD2tIAAAYjOsG+w2rVq2KVatWXXGfUqkUjY2NQx4KAACGY1TOyd29e3fMnDkzbrnllnjooYfi9OnTl923t7c3KpXKgA0AAIZjxCN35cqV8U//9E+xa9eu+Ou//uvo6OiIVatWxcWLFy+5f3t7e5TL5f6tubl5pEcCAOADpqYoimLI31xTEzt37ozVq1dfdp//+q//iptuuil+8pOfxNKlS99zf29vb/T29vZ/XalUorm5Obq7u6Ourm6oo1VVTU1NtUcY04ZxyI0JGdZ3tNcgw89oPBvv6+s9grHOMVp919KJo34JsRtvvDGmT58eR44cueT9pVIp6urqBmwAADAcox65b775Zpw+fTpmzZo12k8FAAARMYSrK5w9e3bAp7LHjh2LgwcPRn19fdTX18fjjz8ea9asicbGxjh69Gg88sgjcfPNN8eKFStGdHAAALicQUfuq6++Gp/73Of6v968eXNERKxduzaefPLJOHToUPzjP/5jnDlzJpqammL58uXxl3/5l1EqlUZuagAAuIJh/eLZaKhUKlEul/3iWWJj7JAbtAzrO95/MYkrG+/r6z2Csc4xWn1j4hfPAADg/SZyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHQGFbnt7e1x6623Rm1tbcycOTNWr14dhw8fHrDPuXPnoq2tLaZNmxY33HBDrFmzJrq6ukZ0aAAAuJJBRW5HR0e0tbXFvn374uWXX44LFy7E8uXLo6enp3+fTZs2xQsvvBDPPvtsdHR0xMmTJ+Puu+8e8cEBAOByaoqiKIb6zb/85S9j5syZ0dHREUuWLInu7u6YMWNG7NixI+65556IiHj99dfj4x//eOzduzduv/32qz5mpVKJcrkc3d3dUVdXN9TRqqqmpqbaI4xpwzjkxoQM6zvaa5DhZzSejff19R7BWOcYrb5r6cRhnZPb3d0dERH19fUREXHgwIG4cOFCLFu2rH+f+fPnx5w5c2Lv3r2XfIze3t6oVCoDNgAAGI4hR25fX19s3Lgx7rjjjliwYEFERHR2dsbkyZNj6tSpA/ZtaGiIzs7OSz5Oe3t7lMvl/q25uXmoIwEAQEQMI3Lb2tritddei2eeeWZYA2zZsiW6u7v7txMnTgzr8QAA4LqhfNP69evjxRdfjD179sTs2bP7b29sbIzz58/HmTNnBnya29XVFY2NjZd8rFKpFKVSaShjAADAJQ3qk9yiKGL9+vWxc+fOeOWVV2LevHkD7l+8eHFMmjQpdu3a1X/b4cOH4/jx49Ha2joyEwMAwFUM6pPctra22LFjRzz//PNRW1vbf55tuVyOKVOmRLlcjnXr1sXmzZujvr4+6urqYsOGDdHa2npNV1YAAICRMKhLiF3ukhNPPfVU3H///RHx6z8G8bWvfS2efvrp6O3tjRUrVsR3v/vdy56u8G4uIZafS69U33i/xBRXNt7X13sEY51jtPqupROHdZ3c0SBy8xtjh9ygZVjf8R5BXNl4X1/vEYx1jtHqG/Xr5AIAwFgkcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOoOK3Pb29rj11lujtrY2Zs6cGatXr47Dhw8P2Oezn/1s1NTUDNgefPDBER0aAACuZFCR29HREW1tbbFv3754+eWX48KFC7F8+fLo6ekZsN8DDzwQp06d6t+eeOKJER0aAACu5LrB7PzSSy8N+Hr79u0xc+bMOHDgQCxZsqT/9g996EPR2Ng4MhMCAMAgDeuc3O7u7oiIqK+vH3D797///Zg+fXosWLAgtmzZEu+8885lH6O3tzcqlcqADQAAhmNQn+T+f319fbFx48a44447YsGCBf23f+lLX4q5c+dGU1NTHDp0KL7+9a/H4cOH44c//OElH6e9vT0ef/zxoY4BAADvUVMURTGUb3zooYfiRz/6UfzsZz+L2bNnX3a/V155JZYuXRpHjhyJm2666T339/b2Rm9vb//XlUolmpubo7u7O+rq6oYyWtXV1NRUe4QxbYiH3JiRYX1Hew0y/IzGs/G+vt4jGOsco9V3LZ04pE9y169fHy+++GLs2bPnioEbEdHS0hIRcdnILZVKUSqVhjIGAABc0qAityiK2LBhQ+zcuTN2794d8+bNu+r3HDx4MCIiZs2aNaQBAQBgsAYVuW1tbbFjx454/vnno7a2Njo7OyMiolwux5QpU+Lo0aOxY8eO+PznPx/Tpk2LQ4cOxaZNm2LJkiWxcOHCUfkPAACAdxvUObmXO4fjqaeeivvvvz9OnDgRf/iHfxivvfZa9PT0RHNzc9x1113xF3/xF9d8fm2lUolyueyc3MScy1R94/2cTa5svK+v9wjGOsdo9Y34OblXW9Tm5ubo6OgYzEMCAMCIG9Z1cgEAYCwSuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgnUFF7pNPPhkLFy6Murq6qKuri9bW1vjRj37Uf/+5c+eira0tpk2bFjfccEOsWbMmurq6RnxoAAC4kkFF7uzZs+Ov/uqv4sCBA/Hqq6/G7//+78cXvvCF+Pd///eIiNi0aVO88MIL8eyzz0ZHR0ecPHky7r777lEZHAAALqemKIpiOA9QX18f3/rWt+Kee+6JGTNmxI4dO+Kee+6JiIjXX389Pv7xj8fevXvj9ttvv6bHq1QqUS6Xo7u7O+rq6oYzWtXU1NRUe4QxbZiHXNVlWN/RXoMMP6PxbLyvr/cIxjrHaPVdSycO+ZzcixcvxjPPPBM9PT3R2toaBw4ciAsXLsSyZcv695k/f37MmTMn9u7de9nH6e3tjUqlMmADAIDhGHTk/tu//VvccMMNUSqV4sEHH4ydO3fG7/zO70RnZ2dMnjw5pk6dOmD/hoaG6OzsvOzjtbe3R7lc7t+am5sH/R8BAAD/36Aj95ZbbomDBw/G/v3746GHHoq1a9fGf/zHfwx5gC1btkR3d3f/duLEiSE/FgAARERcN9hvmDx5ctx8880REbF48eL413/91/i7v/u7uPfee+P8+fNx5syZAZ/mdnV1RWNj42Ufr1QqRalUGvzkAABwGcO+Tm5fX1/09vbG4sWLY9KkSbFr167++w4fPhzHjx+P1tbW4T4NAABcs0F9krtly5ZYtWpVzJkzJ95+++3YsWNH7N69O3784x9HuVyOdevWxebNm6O+vj7q6upiw4YN0draes1XVgAAgJEwqMh966234o/+6I/i1KlTUS6XY+HChfHjH/84/uAP/iAiIv72b/82JkyYEGvWrIne3t5YsWJFfPe73x2VwQEA4HKGfZ3ckeY6ufmNsUNu0DKs73i/jipXNt7X13sEY51jtPpG9Tq5AAAwVolcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDoiFwCAdEQuAADpiFwAANIRuQAApCNyAQBIR+QCAJCOyAUAIB2RCwBAOiIXAIB0RC4AAOmIXAAA0hG5AACkI3IBAEhH5AIAkI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASOe6ag/wbkVRREREpVKp8iSMFmtbfdYgt/G+vuN9fvJzjFbfb3rxSmqKa9nrffTmm29Gc3NztccAAGCMOnHiRMyePfuK+4y5yO3r64uTJ09GbW1t1NTUXHX/SqUSzc3NceLEiairq3sfJuT9Zo1zs765Wd/8rHFuY219i6KIt99+O5qammLChCufdTvmTleYMGHCVcv8Uurq6sbED5/RY41zs765Wd/8rHFuY2l9y+XyNe3nF88AAEhH5AIAkM64j9xSqRRbt26NUqlU7VEYJdY4N+ubm/XNzxrnNp7Xd8z94hkAAAzXuP8kFwAA3k3kAgCQjsgFACAdkQsAQDoiFwCAdMZ95G7bti0+8pGPxPXXXx8tLS3x85//vNojMQK+8Y1vRE1NzYBt/vz51R6LYdizZ0/ceeed0dTUFDU1NfHcc88NuL8oinjsscdi1qxZMWXKlFi2bFm88cYb1RmWQbva+t5///3veU2vXLmyOsMyaO3t7XHrrbdGbW1tzJw5M1avXh2HDx8esM+5c+eira0tpk2bFjfccEOsWbMmurq6qjQxg3Et6/vZz372Pa/hBx98sEoTX5txHbk/+MEPYvPmzbF169b4xS9+EYsWLYoVK1bEW2+9Ve3RGAGf+MQn4tSpU/3bz372s2qPxDD09PTEokWLYtu2bZe8/4knnojvfOc78b3vfS/2798fH/7wh2PFihVx7ty593lShuJq6xsRsXLlygGv6aeffvp9nJDh6OjoiLa2tti3b1+8/PLLceHChVi+fHn09PT077Np06Z44YUX4tlnn42Ojo44efJk3H333VWcmmt1LesbEfHAAw8MeA0/8cQTVZr4GhXj2G233Va0tbX1f33x4sWiqampaG9vr+JUjIStW7cWixYtqvYYjJKIKHbu3Nn/dV9fX9HY2Fh861vf6r/tzJkzRalUKp5++ukqTMhwvHt9i6Io1q5dW3zhC1+oyjyMvLfeequIiKKjo6Moil+/XidNmlQ8++yz/fv853/+ZxERxd69e6s1JkP07vUtiqL4vd/7veJP/uRPqjfUEIzbT3LPnz8fBw4ciGXLlvXfNmHChFi2bFns3bu3ipMxUt54441oamqKG2+8Mb785S/H8ePHqz0So+TYsWPR2dk54PVcLpejpaXF6zmR3bt3x8yZM+OWW26Jhx56KE6fPl3tkRii7u7uiIior6+PiIgDBw7EhQsXBryG58+fH3PmzPEaHofevb6/8f3vfz+mT58eCxYsiC1btsQ777xTjfGu2XXVHmCofvWrX8XFixejoaFhwO0NDQ3x+uuvV2kqRkpLS0ts3749brnlljh16lQ8/vjj8ZnPfCZee+21qK2trfZ4jLDOzs6IiEu+nn9zH+PbypUr4+6774558+bF0aNH48///M9j1apVsXfv3pg4cWK1x2MQ+vr6YuPGjXHHHXfEggULIuLXr+HJkyfH1KlTB+zrNTz+XGp9IyK+9KUvxdy5c6OpqSkOHToUX//61+Pw4cPxwx/+sIrTXtm4jVxyW7VqVf+/Fy5cGC0tLTF37tz453/+51i3bl0VJwOG4otf/GL/vz/5yU/GwoUL46abbordu3fH0qVLqzgZg9XW1havvfaa35NI6nLr+9WvfrX/35/85Cdj1qxZsXTp0jh69GjcdNNN7/eY12Tcnq4wffr0mDhx4nt+c7OrqysaGxurNBWjZerUqfGxj30sjhw5Uu1RGAW/ec16PX9w3HjjjTF9+nSv6XFm/fr18eKLL8ZPf/rTmD17dv/tjY2Ncf78+Thz5syA/b2Gx5fLre+ltLS0RESM6dfwuI3cyZMnx+LFi2PXrl39t/X19cWuXbuitbW1ipMxGs6ePRtHjx6NWbNmVXsURsG8efOisbFxwOu5UqnE/v37vZ6TevPNN+P06dNe0+NEURSxfv362LlzZ7zyyisxb968AfcvXrw4Jk2aNOA1fPjw4Th+/LjX8DhwtfW9lIMHD0ZEjOnX8Lg+XWHz5s2xdu3a+NSnPhW33XZbfPvb346enp74yle+Uu3RGKaHH3447rzzzpg7d26cPHkytm7dGhMnToz77ruv2qMxRGfPnh3wf/zHjh2LgwcPRn19fcyZMyc2btwY3/zmN+OjH/1ozJs3Lx599NFoamqK1atXV29ortmV1re+vj4ef/zxWLNmTTQ2NsbRo0fjkUceiZtvvjlWrFhRxam5Vm1tbbFjx454/vnno7a2tv8823K5HFOmTIlyuRzr1q2LzZs3R319fdTV1cWGDRuitbU1br/99ipPz9VcbX2PHj0aO3bsiM9//vMxbdq0OHToUGzatCmWLFkSCxcurPL0V1DtyzsM19///d8Xc+bMKSZPnlzcdtttxb59+6o9EiPg3nvvLWbNmlVMnjy5+O3f/u3i3nvvLY4cOVLtsRiGn/70p0VEvGdbu3ZtURS/vozYo48+WjQ0NBSlUqlYunRpcfjw4eoOzTW70vq+8847xfLly4sZM2YUkyZNKubOnVs88MADRWdnZ7XH5hpdam0jonjqqaf69/mf//mf4o//+I+L3/qt3yo+9KEPFXfddVdx6tSp6g3NNbva+h4/frxYsmRJUV9fX5RKpeLmm28u/vRP/7To7u6u7uBXUVMURfF+RjUAAIy2cXtOLgAAXI7IBQAgHZELAEA6IhcAgHRELgAA6YhcAADSEbkAAKQjcgEASEfkAgCQjsgFACAdkQsAQDr/CxnQ6a2pkO7tAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(layers[-1].out.abs() > 0.99, cmap='gray', interpolation='nearest') # White is true, black is false\n",
    "\n",
    "# Since we have full white columns, this means that there are dead neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41468feb-c27f-475d-bb60-3855aa01df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------ Exercise 2 ------------------------------\n",
    "# BatchNorm, unlike other normalization layers like LayerNorm/GroupNorm \n",
    "# etc. has the big advantage that after training, the batchnorm gamma/beta \n",
    "# can be \"folded into\" the weights of the preceeding Linear layers, \n",
    "# effectively erasing the need to forward it at test time.\n",
    "#\n",
    "# Set up a small 3-layer MLP with batchnorms, train the network, then \n",
    "# \"fold\" the batchnorm gamma/beta into the preceeding Linear layer's W,b \n",
    "# by creating a new W2, b2 and erasing the batch norm. \n",
    "#\n",
    "# Verify that this gives the same forward pass during inference. i.e. \n",
    "# we see that the batchnorm is there just for stabilizing the training, \n",
    "# and can be thrown out after training is done! pretty cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793ee3ae-1577-4596-a4ea-966b4a21fa37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6297\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # dimensionality of the character embedding vectors\n",
    "n_hidden = 100 # the number of neurons in the hidden layer of the MLP\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd), generator = g)\n",
    "layers = [\n",
    "    Linear(n_embd * block_size, n_hidden), BatchNorm1d(n_hidden), Tanh(), \n",
    "    Linear(n_hidden, vocab_size),\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # last layer: make less confident\n",
    "    # layers[-1].gamma *= 0.1\n",
    "    layers[-1].weight *= 0.1\n",
    "    # all other layers: apply gain\n",
    "    for layer in layers[:-1]:\n",
    "        if isinstance(layer, Linear):\n",
    "            layer.weight *= 5/3\n",
    "            \n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04364d65-8f1b-42db-9ee6-5ce78fde130f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2912\n",
      "  10000/ 200000: 2.4953\n",
      "  20000/ 200000: 2.4687\n",
      "  30000/ 200000: 2.3428\n",
      "  40000/ 200000: 2.1891\n",
      "  50000/ 200000: 2.4408\n",
      "  60000/ 200000: 2.1279\n",
      "  70000/ 200000: 2.2252\n",
      "  80000/ 200000: 2.2386\n",
      "  90000/ 200000: 2.5566\n",
      " 100000/ 200000: 1.8108\n",
      " 110000/ 200000: 2.3478\n",
      " 120000/ 200000: 2.0202\n",
      " 130000/ 200000: 2.2370\n",
      " 140000/ 200000: 2.3931\n",
      " 150000/ 200000: 2.1625\n",
      " 160000/ 200000: 2.1394\n",
      " 170000/ 200000: 1.9499\n",
      " 180000/ 200000: 2.0418\n",
      " 190000/ 200000: 2.0878\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "    \n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb, = Xtr[ix], Ytr[ix] # # batch X, Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad() # AFTER_DEBUG: would take out retain_grad\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 \n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    if i%10000 == 0:\n",
    "        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\n",
    "    lossi.append(loss.log10().item())\n",
    "    with torch.no_grad():\n",
    "        ud.append([(lr*p.grad.std() / p.data.std()).log10().item() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "226bb655-c8e2-4a5f-95ad-77a060847d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layers[1].training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4f4cf0cc-7d31-4bce-aecb-ac1f0fc2550d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0188)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, Yb)\n",
    "    \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2cf3e78c-ab3d-442d-b839-ee673b3d8e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now \"fold\" BatchNorm into Linear somehow :D and get the same loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b9da5508-33a7-409a-8060-710f81ad805b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Linear at 0x14a677e20>,\n",
       " <__main__.Tanh at 0x14a677fa0>,\n",
       " <__main__.Linear at 0x14a677d60>]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "newlayers = copy.deepcopy(layers)\n",
    "del newlayers[1] # Delete BatchNorm from newlayers\n",
    "\n",
    "blayer = copy.deepcopy(layers[1]) # Copy of BatchNorm layer\n",
    "\n",
    "linear = newlayers[0] # variable of Linear layer that preceeded the BatchNorm layer\n",
    "\n",
    "newlayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "899d881f-59fd-4bb2-b451-6038c2867a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking solution exaplined at https://stackoverflow.com/questions/49536856/tensorflow-how-to-merge-batchnorm-into-convolution-for-faster-inference\n",
    "# w_new = gamma * w / np.sqrt(var + epsilon)\n",
    "# b_new = gamma * (b - mean) / np.sqrt(var + epsilon) + beta)\n",
    "\n",
    "with torch.no_grad():\n",
    "    linear.weight = blayer.gamma * linear.weight / torch.sqrt(blayer.running_var + blayer.eps)\n",
    "    linear.bias = blayer.gamma * (linear.bias - blayer.running_mean) / torch.sqrt(blayer.running_var + blayer.eps) + blayer.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "f41baf4d-60eb-4812-958e-d77f8fbea360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0188)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    x = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    for layer in newlayers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, Yb)\n",
    "    \n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066d73a-ad8c-4a7a-8e5e-fce1e4e8122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both losses are the same and the BatchNorm layer is now removed from newlayers NN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
